{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e2b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from math import sqrt\n",
    "import itertools\n",
    "\n",
    "# Load train dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "# Load features dataset and join it with train data\n",
    "features_df = pd.read_csv('features.csv')\n",
    "df = pd.merge(df, features_df.drop(['IsHoliday'], axis = 1), how = 'left', on = ['Store', 'Date'])\n",
    "# Load store dataset and join with above data\n",
    "stores_df = pd.read_csv('stores.csv')\n",
    "df = pd.merge(df, stores_df, how = 'left', on = ['Store'])\n",
    "\n",
    "# Filter data for store 20\n",
    "df = df[df['Store'] == 20]\n",
    "\n",
    "# Impute NULL values\n",
    "df['MarkDown1'] = df['MarkDown1'].fillna(0)\n",
    "df['MarkDown2'] = df['MarkDown2'].fillna(0)\n",
    "df['MarkDown3'] = df['MarkDown3'].fillna(0)\n",
    "df['MarkDown4'] = df['MarkDown4'].fillna(0)\n",
    "df['MarkDown5'] = df['MarkDown5'].fillna(0)\n",
    "\n",
    "# Create year, month, and date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['month_date'] = df['Date'].apply(lambda i : i.month)\n",
    "df['day_date'] = df['Date'].apply(lambda i : i.day)\n",
    "df['year_date'] = df['Date'].apply(lambda i : i.year)\n",
    "\n",
    "# One hot encoding\n",
    "cols_to_encode = ['Type', 'IsHoliday']\n",
    "df = pd.get_dummies(data = df, columns = cols_to_encode, drop_first = True)\n",
    "\n",
    "# Standard Scaler\n",
    "standard_scaler = StandardScaler()\n",
    "feature_cols = ['Temperature', 'Fuel_Price', 'MarkDown1','MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size']\n",
    "transformed_features = standard_scaler.fit_transform(df[feature_cols])\n",
    "df[feature_cols] = transformed_features\n",
    "\n",
    "# Initialize final forecast series\n",
    "final_forecast = pd.Series(dtype='float64')\n",
    "final_actual = pd.Series(dtype='float64')\n",
    "\n",
    "# Initialize performance metrics\n",
    "performance_metrics = []\n",
    "\n",
    "# Iterate through each department in store 20\n",
    "departments = df['Dept'].unique()\n",
    "for dept in departments:\n",
    "    dept_df = df[df['Dept'] == dept]\n",
    "    \n",
    "    # Time Series Analysis\n",
    "    sales_data = dept_df.groupby('Date')['Weekly_Sales'].sum().sort_index()\n",
    "    \n",
    "    # Perform the Augmented Dickey-Fuller test to check for stationarity\n",
    "    adf_test = adfuller(sales_data)\n",
    "    adf_p_value = adf_test[1]\n",
    "    \n",
    "    # Determine the number of lags\n",
    "    max_lags = min(40, len(sales_data) // 2)\n",
    "    \n",
    "    # Define train and test sets\n",
    "    train_size = int(len(sales_data) * 0.8)\n",
    "    train = sales_data[:train_size]\n",
    "    test = sales_data[train_size:]\n",
    "    \n",
    "    # Auto ARIMA to find best p, d, q\n",
    "    p = d = q = range(0, 3)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    \n",
    "    # Evaluate models\n",
    "    best_aic = float(\"inf\")\n",
    "    best_pdq = None\n",
    "    best_model = None\n",
    "    \n",
    "    for param in pdq:\n",
    "        try:\n",
    "            temp_model = ARIMA(train, order=param)\n",
    "            temp_result = temp_model.fit()\n",
    "            if temp_result.aic < best_aic:\n",
    "                best_aic = temp_result.aic\n",
    "                best_pdq = param\n",
    "                best_model = temp_result\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Forecast using the best model\n",
    "    forecast_steps = len(test)\n",
    "    forecast = best_model.get_forecast(steps=forecast_steps)\n",
    "    forecast_df = forecast.summary_frame()\n",
    "    forecast_values = forecast_df['mean']\n",
    "    \n",
    "    # Aggregate the forecast and actual values\n",
    "    if final_forecast.empty:\n",
    "        final_forecast = forecast_values\n",
    "        final_actual = test\n",
    "    else:\n",
    "        final_forecast = final_forecast.add(forecast_values, fill_value=0)\n",
    "        final_actual = final_actual.add(test, fill_value=0)\n",
    "    \n",
    "    # Calculate performance metrics for the best model\n",
    "    mse = mean_squared_error(test, forecast_values)\n",
    "    rmse = sqrt(mse)\n",
    "    mae = mean_absolute_error(test, forecast_values)\n",
    "    mape = np.mean(np.abs((test - forecast_values) / test)) * 100\n",
    "    r2 = r2_score(test, forecast_values)\n",
    "    \n",
    "    performance_metrics.append({\n",
    "        'Dept': dept,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "# Save performance metrics to a file\n",
    "performance_df = pd.DataFrame(performance_metrics)\n",
    "performance_df.to_csv('performance_metrics.csv', index=False)\n",
    "\n",
    "# Save summary of the best model for the last department processed\n",
    "with open('best_model_summary.txt', 'w') as f:\n",
    "    f.write(\"Best Model Summary:\\n\")\n",
    "    f.write(str(best_model.summary()))\n",
    "    f.write(f\"\\nBest pdq: {best_pdq}\\n\")\n",
    "\n",
    "# Calculate performance metrics for the final aggregated model\n",
    "final_mse = mean_squared_error(final_actual, final_forecast)\n",
    "final_rmse = sqrt(final_mse)\n",
    "final_mae = mean_absolute_error(final_actual, final_forecast)\n",
    "final_mape = np.mean(np.abs((final_actual - final_forecast) / final_actual)) * 100\n",
    "final_r2 = r2_score(final_actual, final_forecast)\n",
    "\n",
    "# Save final aggregated performance metrics to a file\n",
    "with open('final_aggregated_performance_metrics.txt', 'w') as f:\n",
    "    f.write(f\"Final Aggregated MSE: {final_mse}\\n\")\n",
    "    f.write(f\"Final Aggregated RMSE: {final_rmse}\\n\")\n",
    "    f.write(f\"Final Aggregated MAE: {final_mae}\\n\")\n",
    "    f.write(f\"Final Aggregated MAPE: {final_mape}\\n\")\n",
    "    f.write(f\"Final Aggregated R2: {final_r2}\\n\")\n",
    "\n",
    "# Plot the final aggregated forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(final_forecast.index, final_forecast, label='Aggregated Forecast', color='blue')\n",
    "plt.plot(final_actual.index, final_actual, label='Actual Sales', color='orange')\n",
    "plt.title('Aggregated ARIMA Model Forecast for Store 20')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.legend()\n",
    "plt.savefig('aggregated_forecast_plot.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
